{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec - Continuous Bag of Words model\n",
    "\n",
    "This notebook consists of the tensorflow implementation of the model.\n",
    "\n",
    "For more information about the model, check out the following research papers:\n",
    "1. <a href = \"https://arxiv.org/pdf/1301.3781.pdf\">Efficient Estimation of Word Representations in Vector Space</a>\n",
    "2. <a href = \"https://arxiv.org/pdf/1310.4546.pdf\">Distributed Representations of Words and Phrases and their Compositionality</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Defining Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['the dog saw a cat',\n",
    "          'the dog chased the cat',\n",
    "          'the cat climbed a tree'\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(corpus):\n",
    "    stop_words = {\"the\", \"a\", \"is\", \"an\"}\n",
    "    \n",
    "    transformed_sentences = []\n",
    "    for sentence in corpus:\n",
    "        result = []\n",
    "        for word in sentence.split(\" \"):\n",
    "            if word not in stop_words:\n",
    "                result.append(word)\n",
    "        transformed_sentences.append(\" \".join(result))\n",
    "    return transformed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog saw cat', 'dog chased cat', 'cat climbed tree']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = remove_stopwords(corpus)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Constructing vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dictionary: 6\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "for sentence in sentences:\n",
    "    for word in sentence.split(\" \"):\n",
    "        vocab.add(word)\n",
    "\n",
    "dict_size = len(vocab)\n",
    "print(\"Size of the dictionary: {}\".format(dict_size))\n",
    "print('the' in vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [sentence.split(\" \") for sentence in sentences]\n",
    "\n",
    "# Assigning unique integer value to each word in the dictionary\n",
    "wordPos = {}\n",
    "for idx, word in enumerate(vocab):\n",
    "    wordPos[word] = idx\n",
    "\n",
    "# Setting hyperparameters\n",
    "window_size = 1\n",
    "wordvec_dimension = 2\n",
    "\n",
    "\n",
    "data = []\n",
    "for sentence in sentences:\n",
    "    for idx, word in enumerate(sentence):\n",
    "        context_words = []\n",
    "        for neighbor in sentence[max(idx-window_size, 0): min(idx+window_size, len(sentence))+1]:\n",
    "            if neighbor is not word:\n",
    "                context_words.append(neighbor)\n",
    "        data.append([context_words, word])\n",
    "\n",
    "# Size of our data\n",
    "m = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      context    word\n",
      "0       [saw]     dog\n",
      "1  [dog, cat]     saw\n",
      "2       [saw]     cat\n",
      "3    [chased]     dog\n",
      "4  [dog, cat]  chased\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data, columns = ['context', 'word'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def one_hot(word):\n",
    "    vec = np.zeros(dict_size)\n",
    "    vec[wordPos[word]] = 1\n",
    "    return vec\n",
    "\n",
    "def list_to_vec(getlist):\n",
    "    vec = np.zeros(dict_size)\n",
    "    for word in getlist:\n",
    "        vec[wordPos[word]] = 1\n",
    "    return vec\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for getlist, word in zip(df['context'], df['word']):\n",
    "    X_train.append(list_to_vec(getlist))\n",
    "    y_train.append(one_hot(word))\n",
    "    \n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1.]]\n",
      "(9, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:5])\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "(9, 6)\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:5])\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Defining tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = (None, dict_size))\n",
    "y = tf.placeholder(tf.float32, shape = (None, dict_size))\n",
    "\n",
    "# Hidden layer parameters\n",
    "w1 = tf.Variable(tf.random_normal((dict_size, wordvec_dimension)))\n",
    "b1 = tf.Variable(tf.random_normal((1,)))\n",
    "\n",
    "# Hidden layer\n",
    "vectors = tf.add(tf.matmul(X, w1), b1) \n",
    "\n",
    "# Output layer parameters\n",
    "w2 = tf.Variable(tf.random_normal((wordvec_dimension, dict_size)))\n",
    "b2 = tf.Variable(tf.random_normal((1,)))\n",
    "\n",
    "# Output layer\n",
    "prediction = tf.nn.softmax(tf.add(tf.matmul(vectors, w2), b2))\n",
    "\n",
    "# Objective function [to minimize]\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y_train * tf.log(prediction), axis = 1))\n",
    "\n",
    "# Model\n",
    "model = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Running above tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at 5000 iteration: 0.6183262467384338\n",
      "Cost at 10000 iteration: 0.6169877648353577\n",
      "Cost at 15000 iteration: 0.6166402101516724\n",
      "Cost at 20000 iteration: 0.6164863705635071\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "initializer = tf.global_variables_initializer()\n",
    "sess.run(initializer)\n",
    "\n",
    "max_iters = 20000\n",
    "for itr in range(1, max_iters+1):\n",
    "    sess.run(model, feed_dict = {X: X_train, y: y_train})\n",
    "    \n",
    "    if itr % 5000 == 0:\n",
    "        itr_cost = sess.run(loss, feed_dict = {X: X_train, y: y_train})\n",
    "        print(\"Cost at {} iteration: {}\".format(itr, itr_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordVectors = sess.run(w1+b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      word  x-coordinate  y-coordinate\n",
      "0  climbed     -0.634748      4.149545\n",
      "1      cat      1.194917     -2.025758\n",
      "2   chased      2.512901      2.437788\n",
      "3     tree      2.497783      0.557932\n",
      "4      saw      2.503366      2.428549\n",
      "5      dog     -1.915064     -0.558117\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(wordVectors, columns = ['x-coordinate', 'y-coordinate'])\n",
    "data['word'] = vocab\n",
    "data = data[['word', 'x-coordinate', 'y-coordinate']]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Projecting wordVectors to 2D plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for word, x, y in zip(data['word'], data['x-coordinate'], data['y-coordinate']):\n",
    "    ax.annotate(word, (x, y))\n",
    "\n",
    "PADDING = 1.0\n",
    "x_axis_min = np.amin(wordVectors, axis=0)[0] - PADDING\n",
    "y_axis_min = np.amin(wordVectors, axis=0)[1] - PADDING\n",
    "x_axis_max = np.amax(wordVectors, axis=0)[0] + PADDING\n",
    "y_axis_max = np.amax(wordVectors, axis=0)[1] + PADDING\n",
    " \n",
    "plt.xlim(x_axis_min,x_axis_max)\n",
    "plt.ylim(y_axis_min,y_axis_max)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
